{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're logging :)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "log = logger(True) ; log(\"We're logging :)\")\n",
    "\n",
    "# Auto-reloading of modules in iPython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# CONSTANT\n",
    "SAVE_EVERY = 20\n",
    "SEQ_SIZE = 50\n",
    "RANDOM_SEED = 11\n",
    "VALIDATION_SIZE = 0.15\n",
    "LR = 1e-3\n",
    "N_EPOCHS = 100\n",
    "NUM_LAYERS, HIDDEN_SIZE = 1, 100\n",
    "DROPOUT_P = 0\n",
    "model_type = 'lstm'\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "INPUT = 'data/music_notation.txt'  \n",
    "INP_LYRICS = 'data/lyrics.txt' \n",
    "TEST_INPUT = 'data/test.txt'\n",
    "SAVED_ABC = 'data/output.abc'\n",
    "RESUME = True\n",
    "CHECKPOINT = 'ckpt_mdl_{}_ep_{}_hsize_{}_dout_{}_RMSprop'.format(model_type, N_EPOCHS, HIDDEN_SIZE, DROPOUT_P)\n",
    "GENERATION_MAX_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Data loaded\n"
     ]
    }
   ],
   "source": [
    "# READ IN DATA FILE\n",
    "f = open(INPUT,\"r\")\n",
    "data, buffer = [], ''\n",
    "store = False\n",
    "for line in f:\n",
    "    if line == '||\\n':\n",
    "        data += [buffer]\n",
    "        buffer = ''\n",
    "    else:\n",
    "        buffer += line\n",
    "f.close()\n",
    "\n",
    "# We only want songs which are at least as big as our batch size +1\n",
    "data = [ song for song in data if len(song) > SEQ_SIZE + 10 ]\n",
    "\n",
    "log('=====> Data loaded')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].split('K:')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Lyrics loaded\n"
     ]
    }
   ],
   "source": [
    "# READ A LYRICS FILE\n",
    "f = open(INP_LYRICS,\"r\")\n",
    "lyrics = f.read().split('||')\n",
    "lyrics = [sent.replace('\\n', ' ').lstrip(' ').rstrip(' ') for sent in lyrics]\n",
    "log('=====> Lyrics loaded')\n",
    "\n",
    "for i, sentence in enumerate(lyrics):\n",
    "    words = sentence.split(' ')[:SEQ_SIZE]\n",
    "    sent = ' '.join(words)\n",
    "    lyrics[i] = sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Test Lyrics loaded\n"
     ]
    }
   ],
   "source": [
    "# READ A LYRICS FILE\n",
    "f = open(TEST_INPUT,\"r\")\n",
    "test_input = f.read()\n",
    "log('=====> Test Lyrics loaded')\n",
    "\n",
    "words = test_input.replace('\\n', ' ').split(' ')[:SEQ_SIZE]\n",
    "test_input = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 93\n",
      "Original data length: 468\n",
      "Training data length: 398\n",
      "Validation data length: 70\n"
     ]
    }
   ],
   "source": [
    "# for character index encoding\n",
    "char_idx = ''.join(set(list(open(INPUT,'r').read())))\n",
    "char_list = list(char_idx)\n",
    "\n",
    "# for words encoding\n",
    "vocab = []\n",
    "for sentence in lyrics:\n",
    "    vocab.extend(sentence.split(' ')) \n",
    "vocab = set(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_ix[\"UNK\"] = len(word_to_ix)\n",
    "\n",
    "# NOW SPLIT INTO TRAIN/VALIDATION SETS\n",
    "num_train = len(data)\n",
    "indices = list(range(num_train))\n",
    "split_idx = int(np.floor(VALIDATION_SIZE * num_train))\n",
    "\n",
    "# Shuffle data and split\n",
    "np.random.seed(RANDOM_SEED)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idxs, valid_idxs = indices[split_idx:], indices[:split_idx]\n",
    "train_len, valid_len = len(train_idxs), len(valid_idxs)\n",
    "log('Number of unique characters: %s' % len(char_idx))\n",
    "log('Original data length: %s' % len(data))\n",
    "log('Training data length: %s'% train_len)\n",
    "log('Validation data length: %s' % valid_len)\n",
    "assert(train_len + valid_len == len(data)), 'Train_len + valid_len should == len(data)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Utility functions loaded.\n"
     ]
    }
   ],
   "source": [
    "# Utility functions\n",
    "def tic(): return time.time()\n",
    "\n",
    "\n",
    "def toc(tic, msg=None):\n",
    "    s = time.time() - tic\n",
    "    m = int(s / 60)\n",
    "    if msg:\n",
    "        return '{}m {}s {}'.format(m, int(s - (m * 60)), msg)\n",
    "    return '{}m {}s'.format(m, int(s - (m * 60)))\n",
    "\n",
    "\n",
    "# Gives us a random slice of size SEQ_SIZE + 1 so we can get a train/target.\n",
    "def rand_slice(data, slice_len=SEQ_SIZE):\n",
    "    d_len = len(data)\n",
    "    s_idx = random.randint(0, d_len - slice_len)\n",
    "    e_idx = s_idx + slice_len + 1\n",
    "    return data[s_idx:e_idx]\n",
    "\n",
    "\n",
    "def seq_to_tensor(seq):\n",
    "    '''\n",
    "    create tensor from char seq\n",
    "    '''\n",
    "    out = torch.zeros(len(seq)).long()\n",
    "    for i, c in enumerate(seq):\n",
    "        out[i] = char_idx.index(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def train_slice(data, slice_len=50):\n",
    "    '''\n",
    "    creates a random training set\n",
    "    '''\n",
    "    slice_i = rand_slice(data, slice_len=slice_len)\n",
    "    seq = seq_to_tensor(slice_i[:-1])\n",
    "    target = seq_to_tensor(slice_i[1:])\n",
    "    return Variable(seq), Variable(target)\n",
    "\n",
    "\n",
    "def train_batch(data, b_size=100, slice_len=50):\n",
    "    batch_seq = torch.zeros(b_size, slice_len).long()\n",
    "    batch_target = torch.zeros(b_size, slice_len).long()\n",
    "    for idx in range(b_size):\n",
    "        seq, target = train_slice(data, slice_len=slice_len)\n",
    "        batch_seq[idx] = seq.data\n",
    "        batch_target[idx] = target.data\n",
    "    return Variable(batch_seq), Variable(batch_target)\n",
    "\n",
    "\n",
    "def lyrics_to_tensor(lyrics):\n",
    "    '''\n",
    "    create tensor from lyrics\n",
    "    '''\n",
    "    context_idxs = torch.zeros(SEQ_SIZE).long()\n",
    "    for i, w in enumerate(lyrics.split(' ')):\n",
    "        if i==SEQ_SIZE:\n",
    "            break\n",
    "        try:\n",
    "            context_idxs[i] = word_to_ix[w]\n",
    "        except:\n",
    "            pass\n",
    "    return context_idxs\n",
    "\n",
    "# Given a song, return a sequence/target as a variable\n",
    "def song_to_seq_target(song, lyrics):\n",
    "    a_slice = rand_slice(song)\n",
    "    seq = seq_to_tensor(a_slice[:-1])\n",
    "    target = seq_to_tensor(a_slice[1:])\n",
    "    text_seq = lyrics_to_tensor(lyrics)\n",
    "    assert(len(seq) == len(target)), 'SEQ AND TARGET MISMATCH'\n",
    "    return Variable(seq), Variable(target), Variable(text_seq)\n",
    "\n",
    "print(\"=====> Utility functions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> Defining model\n"
     ]
    }
   ],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, text_input_size, input_size, hidden_size, output_size, model='gru', num_layers=1):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.model = model\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.text_embeddings = nn.Embedding(text_input_size, hidden_size)\n",
    "        self.embeddings = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == 'lstm':\n",
    "            self.rnn1 = nn.LSTM(hidden_size * 2, hidden_size, num_layers)\n",
    "            self.rnn2 = nn.LSTM(hidden_size, hidden_size, num_layers)\n",
    "        elif self.model == 'gru':\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.drop = nn.Dropout(p=DROPOUT_P)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        if self.model == 'lstm':\n",
    "            self.hidden = (Variable(torch.zeros(self.num_layers, 1, self.hidden_size)),\n",
    "                           Variable(torch.zeros(self.num_layers, 1, self.hidden_size)))\n",
    "        elif self.model == 'gru':\n",
    "            self.hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    " \n",
    "\n",
    "    def forward(self, seq, lyrics):\n",
    "        embeds = self.embeddings(seq.view(1, -1)).view(1,1,-1) \n",
    "        text_embeds = self.text_embeddings(lyrics.view(1, -1))#.view(1,1,-1) \n",
    "        combined_embeds = torch.cat((embeds, text_embeds), 2)\n",
    "        rnn_out, self.hidden = self.rnn1(combined_embeds, self.hidden)\n",
    "        rnn_out = self.drop(rnn_out)\n",
    "        rnn_out, self.hidden = self.rnn2(rnn_out, self.hidden)\n",
    "        rnn_out = self.drop(rnn_out)\n",
    "        output = self.out(rnn_out.view(1,-1)) \n",
    "        return output\n",
    "    \n",
    "    \n",
    "print('=====> Defining model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pass(seq, target, text_seq, fit=True):\n",
    "    model.init_hidden() \n",
    "    model.zero_grad()   \n",
    "    loss = 0\n",
    "    for i, c in enumerate(seq):\n",
    "        output = model(c, text_seq[i])\n",
    "        loss += loss_function(output, target[i].unsqueeze(0))\n",
    "        \n",
    "    if fit:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.data.item() / len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "RESUME = False\n",
    "if RESUME:\n",
    "        try:\n",
    "            # Load checkpoint.\n",
    "            print('==> Resuming from checkpoint..')\n",
    "            assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "\n",
    "            # load the previously trained model\n",
    "            checkpoint = torch.load('./checkpoint/checkpoint1.pth.tar')\n",
    "            model = checkpoint['model']\n",
    "            loss = checkpoint['loss']\n",
    "            v_loss = checkpoint['v_loss']\n",
    "            losses = checkpoint['losses']\n",
    "            v_losses = checkpoint['v_losses']\n",
    "        except:\n",
    "            print('No Pre-trained model found.')\n",
    "            print('==> Building model..')\n",
    "            in_size, out_size, text_in_size = len(char_idx), len(char_idx), len(word_to_ix)\n",
    "            model = MusicRNN(text_in_size, in_size, HIDDEN_SIZE, out_size, model_type, NUM_LAYERS) #to do\n",
    "            loss, v_loss = 0, 0\n",
    "            losses, v_losses = [], []\n",
    "else:\n",
    "    print('==> Building model..')\n",
    "    in_size, out_size, text_in_size = len(char_idx), len(char_idx), len(word_to_ix)\n",
    "    model = MusicRNN(text_in_size, in_size, HIDDEN_SIZE, out_size, model_type, NUM_LAYERS) #to do\n",
    "    loss, v_loss = 0, 0\n",
    "    losses, v_losses = [], []\n",
    "\n",
    "start_epoch = 0\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "# tried out various optimizers\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "# optimizer = torch.optim.Adagrad(model.parameters())\n",
    "# optimizer = torch.optim.RMSprop(model.parameters())\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 0, 15.08% iter: 59 Time: 0m 44s Loss: 2.573"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-293a2ca20ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msong_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mthis_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msong_to_seq_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msong_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msong_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mthis_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-95eb16b4ae70>\u001b[0m in \u001b[0;36mtrain_pass\u001b[1;34m(seq, target, text_seq, fit)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "time_since = tic()\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    \n",
    "    # Training\n",
    "    for i, song_idx in enumerate(train_idxs):\n",
    "        this_loss = train_pass(*song_to_seq_target(data[song_idx], lyrics[song_idx])) #modified\n",
    "        loss += this_loss\n",
    "        \n",
    "        msg = '\\rTraining Epoch: {}, {:.2f}% iter: {} Time: {} Loss: {:.4}'.format(\n",
    "             epoch, (i+1)/len(train_idxs)*100, i, toc(time_since), this_loss)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    losses.append(loss / len(train_idxs))\n",
    "        \n",
    "    # Validation\n",
    "    for i, song_idx in enumerate(valid_idxs):\n",
    "        this_loss = train_pass(*song_to_seq_target(data[song_idx], lyrics[song_idx]), fit=False)\n",
    "        v_loss += this_loss\n",
    "        \n",
    "        msg = '\\rValidation Epoch: {}, {:.2f}% iter: {} Time: {} Loss: {:.4}'.format(\n",
    "             epoch, (i+1)/len(valid_idxs)*100, i, toc(time_since), this_loss)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    v_losses.append(v_loss / len(valid_idxs))\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    if epoch % SAVE_EVERY == 0 and start_epoch != epoch or epoch == N_EPOCHS - 1:\n",
    "        print('=======>Saving..')\n",
    "        state = {\n",
    "            'model': model,\n",
    "            'loss': losses[-1],\n",
    "            'v_loss': v_losses[-1],\n",
    "            'losses': losses,\n",
    "            'v_losses': v_losses,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "#         torch.save({'state_dict': model.state_dict()}, './checkpoint/checkpoint.pth.tar')\n",
    "        torch.save(state, './checkpoint/checkpoint1.pth.tar')\n",
    "    \n",
    "    loss, v_loss = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss over training and validation data \n",
    "plt.rc('font', size=12)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=12)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=0)      # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=12)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=12)    # legend fontsize\n",
    "plt.rc('figure', titlesize=12)   # fontsize of the figure title\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.plot(v_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_song(prime_str='<start>', lyrics = \"Children, go where I send thee, How shall I send thee?\", max_len=1000, temp=0.8):\n",
    "    model.init_hidden()\n",
    "    \n",
    "    # \"build up\" hidden state using the beginging of a song '<start>'\n",
    "    creation = '<start>'\n",
    "    prime = Variable(seq_to_tensor(creation))\n",
    "    for i in range(len(prime)-1):\n",
    "        _ = model(prime[i], lyrics_to_tensor(lyrics)[i])\n",
    "\n",
    "    # Generate rest of sequence\n",
    "    for j in range(max_len):\n",
    "        out = model(Variable(seq_to_tensor(creation[-1])), lyrics_to_tensor(lyrics)[0]).data.view(-1)\n",
    "        \n",
    "        out = np.array(np.exp(out/temp))\n",
    "        dist = out / np.sum(out)\n",
    "\n",
    "        # Add predicted character to string and use as next input        \n",
    "        creation += char_idx[np.random.choice(len(dist), p=dist)]\n",
    "        if creation[-5:] == '<end>':\n",
    "            break\n",
    "\n",
    "    return creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing string\n",
    "if len(test_input.split(' '))>=SEQ_SIZE:\n",
    "    test_input = ' '.join(test_input.split(' ')[:50])\n",
    "    print('getting only 50 words of text input.')\n",
    "log(write_song(lyrics = test_input, max_len=GENERATION_MAX_LENGTH, temp=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
